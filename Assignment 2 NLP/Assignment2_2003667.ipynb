{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from nltk import re\n",
    "import en_core_web_sm\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "stop_words = STOP_WORDS\n",
    "digits = string.digits\n",
    "verbose=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_word(raw_word,all_words):\n",
    "    word=raw_word.lower()\n",
    "    word=stemmer.lemmatize(word)\n",
    "    if len(word)<=2 or any(map(str.isdigit, word)) or word in stop_words: \n",
    "        return None\n",
    "    else:\n",
    "        all_words.append(word)\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_review(review,all_words):\n",
    "    for w in review[:]:\n",
    "        word_res=clean_word(w,all_words)\n",
    "        if word_res!=None:\n",
    "            review[review.index(w)]=word_res\n",
    "        else:\n",
    "            review.remove(w)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_documents():\n",
    "    documents=[]\n",
    "    all_words=[]\n",
    "    for category in movie_reviews.categories():\n",
    "        for fileid in movie_reviews.fileids(category):\n",
    "            review=list(movie_reviews.words(fileid))\n",
    "            review=clean_review(review,all_words)\n",
    "            documents.append((review, category))\n",
    "    if verbose==1:\n",
    "        print (len(documents))\n",
    "        print(documents[1])\n",
    "    return documents,all_words\n",
    "\n",
    "# In[17]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_most_common_words(feat_num,all_words):\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "    \n",
    "    most_common_words=all_words.most_common(feat_num)\n",
    "    if verbose==1:\n",
    "        print(len(all_words))\n",
    "        print(*most_common_words[:100], sep='\\n')\n",
    "        print(len(most_common_words))\n",
    "    return most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selector(most_common_words):\n",
    "    nlp = en_core_web_sm.load()\n",
    "    word_features=list()\n",
    "    for word in most_common_words:\n",
    "        docs = nlp(word[0])\n",
    "        if docs[0].pos_==\"ADJ\" or docs[0].pos_==\"VERB\" or docs[0].pos_==\"ADV\":\n",
    "            word_features.append(docs[0].text)\n",
    "    return word_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_documents_feature_sets(documents,word_features):\n",
    "    balanced_documents=[]\n",
    "    for i in range(0,int(len(documents)/2)):\n",
    "            balanced_documents.append(documents[i])\n",
    "            balanced_documents.append(documents[i+int(len(documents)/2)])\n",
    "    featuresets = [(find_features(rev,documents,word_features), category) for (rev, category) in balanced_documents]\n",
    "    random.shuffle(featuresets)\n",
    "    if verbose==1:\n",
    "        print (len(featuresets[1][0].keys()))\n",
    "        balanced_documents[:2]\n",
    "    return featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_features(document,documents,word_features):\n",
    "    words = set(document)\n",
    "    features_prob = {}\n",
    "    for w in word_features:\n",
    "        word_freq = document.count(w) / len(documents)\n",
    "        features_prob[w] = word_freq  ## compute frequency\n",
    "    return features_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(cm):\n",
    "    TP=cm._confusion[1][1]\n",
    "    FP=cm._confusion[1][0]\n",
    "    TN=cm._confusion[0][0]\n",
    "    FN=cm._confusion[0][1]\n",
    "\n",
    "    Recall=TP/(TP+FN)\n",
    "    Precision=TP/(TP+FP)\n",
    "    accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    F1score=2*(Recall * Precision) / (Recall + Precision)\n",
    "    if verbose==1:\n",
    "        print(\"Recall is - \",Recall)\n",
    "        print(\"Precision is - \",Precision)\n",
    "        print(\"accuracy is - \",accuracy)\n",
    "        print(\"F1score is - \",F1score)\n",
    "    return Recall,Precision,accuracy,F1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Naive_Bayes_classification_system(feat_num,all_words):\n",
    "    most_common_words=get_most_common_words(feat_num,all_words)\n",
    "    word_features=feature_selector(most_common_words)\n",
    "    if verbose==1:\n",
    "        print (word_features[:100])\n",
    "        print(len(word_features))\n",
    "    featuresets=get_documents_feature_sets(documents,word_features)\n",
    "    if verbose==1:\n",
    "        print(len(featuresets))\n",
    "\n",
    "    # set that we'll train our classifier with\n",
    "    separator=int(len(featuresets)*0.9)\n",
    "    training_set = featuresets[:separator]\n",
    "    # set that we'll test against.\n",
    "    testing_set = featuresets[separator:]\n",
    "\n",
    "    # In[18]:\n",
    "    classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "    testing_set_content=[i[0] for i in testing_set]\n",
    "    golden_label=[i[1] for i in testing_set]\n",
    "    tested_label=classifier.classify_many(testing_set_content)\n",
    "    cm = nltk.ConfusionMatrix(golden_label, tested_label)\n",
    "    if verbose==1:\n",
    "        print (cm)\n",
    "        print(\"Classifier accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "        classifier.show_most_informative_features(50)\n",
    "\n",
    "    Recall,Precision,accuracy,F1score=calculate_metrics(cm)\n",
    "    all_words=[]\n",
    "    return [Recall,Precision,accuracy,F1score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAverageResults(results):\n",
    "    Av_Recall=0\n",
    "    Av_Precision=0\n",
    "    Av_accuracy=0\n",
    "    Av_F1score=0\n",
    "    for result in results:\n",
    "        Av_Recall+=result[0]/len(results)\n",
    "        Av_Precision+=result[1]/len(results)\n",
    "        Av_accuracy+=result[2]/len(results)\n",
    "        Av_F1score+=result[3]/len(results)\n",
    "    return {\"Average Recall\":\"{:.3%}\".format(Av_Recall), \"Average Precision\":\"{:.3%}\".format(Av_Precision), \"Average accuracy\":\"{:.3%}\".format(Av_accuracy), \"Average F1 score\":\"{:.3%}\".format(Av_F1score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_classification_system(tests, all_words,tests_num=3):\n",
    "    for t in tests:\n",
    "        i=0\n",
    "        av_results=[]\n",
    "        while i<tests_num:\n",
    "            av_results.append(run_Naive_Bayes_classification_system(t,all_words))    \n",
    "            i=i+1\n",
    "        print({str(t)+\" movie reviews\":countAverageResults(av_results)})\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1000 movie reviews': {'Average Recall': '81.010%', 'Average Precision': '75.068%', 'Average accuracy': '78.500%', 'Average F1 score': '77.851%'}}\n",
      "{'2000 movie reviews': {'Average Recall': '86.071%', 'Average Precision': '68.037%', 'Average accuracy': '77.333%', 'Average F1 score': '75.992%'}}\n",
      "{'4000 movie reviews': {'Average Recall': '83.851%', 'Average Precision': '71.870%', 'Average accuracy': '79.667%', 'Average F1 score': '77.252%'}}\n",
      "{'8000 movie reviews': {'Average Recall': '83.138%', 'Average Precision': '74.506%', 'Average accuracy': '79.500%', 'Average F1 score': '78.413%'}}\n",
      "{'10000 movie reviews': {'Average Recall': '83.999%', 'Average Precision': '72.730%', 'Average accuracy': '79.167%', 'Average F1 score': '77.931%'}}\n",
      "{'15000 movie reviews': {'Average Recall': '83.498%', 'Average Precision': '72.222%', 'Average accuracy': '80.667%', 'Average F1 score': '77.436%'}}\n",
      "{'20000 movie reviews': {'Average Recall': '81.820%', 'Average Precision': '77.455%', 'Average accuracy': '81.167%', 'Average F1 score': '79.567%'}}\n"
     ]
    }
   ],
   "source": [
    "documents,all_w = create_documents()\n",
    "all_words=all_w\n",
    "test_classification_system([1000,2000,4000,8000,10000,15000,20000],all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
